"use strict";(self.webpackChunkvyckey_computer_notes=self.webpackChunkvyckey_computer_notes||[]).push([[5887],{91592:e=>{e.exports=JSON.parse('{"tag":{"label":"triton","permalink":"/ai/tags/triton","allTagsPath":"/ai/tags","count":1,"items":[{"id":"framework/triton/index","title":"Triton","description":"Triton Inference Server provides a cloud and edge inferencing solution optimized for both CPUs and GPUs. Triton supports an HTTP/REST and GRPC protocol that allows remote clients to request inferencing for any model being managed by the server. For edge deployments, Triton is available as a shared library with a C API that allows the full functionality of Triton to be included directly in an application.","permalink":"/ai/framework/triton/"}],"unlisted":false}}')}}]);